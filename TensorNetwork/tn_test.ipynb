{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tnrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,\"../\")\n",
    "import data_generator as gen\n",
    "import TensorNetwork as tn\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Add description\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.data[index], self.label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data, label, train_perc, val_perc, train_batch_size, val_batch_size, test_batch_size):\n",
    "    \"\"\"\n",
    "    Add description\n",
    "    \"\"\"\n",
    "    \n",
    "    def psi(x):\n",
    "        x = np.array((np.sin(np.pi*x/2),np.cos(np.pi*x/2)))\n",
    "        return np.transpose(x, [1,2,0])\n",
    "\n",
    "\n",
    "    # flatten images\n",
    "    x = data.reshape(len(data),-1)\n",
    "    # embedd them\n",
    "    x = psi(x)\n",
    "    \n",
    "    # training/test splitting\n",
    "    m = int(len(x)*train_perc)\n",
    "    x_train= x[:m]\n",
    "    y_train = label[:m]\n",
    "    x_test =  x[m:]\n",
    "    y_test = label[m:]\n",
    "    \n",
    "    # define custom NumpyDatasets\n",
    "    train_set = NumpyDataset(x_train, y_train)\n",
    "    test_set =  NumpyDataset(x_test, y_test)\n",
    "   \n",
    "    train_len = int(m*(1-val_perc))\n",
    "    train_sampler = SubsetRandomSampler(np.arange(train_len))\n",
    "    val_sampler = SubsetRandomSampler(np.arange(train_len,m))\n",
    "\n",
    "    train_loader = DataLoader(train_set, train_batch_size, sampler=train_sampler, drop_last=True, collate_fn=lambda x: x)\n",
    "    val_loader = DataLoader(train_set, val_batch_size, sampler=val_sampler, drop_last=True, collate_fn=lambda x: x)\n",
    "    test_loader = DataLoader(test_set, test_batch_size, drop_last=False, collate_fn=lambda x: x)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000\n",
    "linear_dim = 5\n",
    "M = 20\n",
    "B = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data, label) = gen.create_dataset(n_samples, linear_dim=linear_dim, sigma=0.5)\n",
    "batch_size = {'train_batch_size':B, 'val_batch_size':128, 'test_batch_size':128}\n",
    "train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TensorNetwork' from '/home/nicola/Nicola_unipd/QuintoAnno/Quantum Information/TensorNetworkForML/TensorNetwork/TensorNetwork.py'>"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_batch = next(iter(train_loader))\n",
    "x_calibration = np.array([calibration_batch[i][0] for i in range(len(calibration_batch))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing weights...\n",
      "Scaling factor: 12.80\n",
      "(32, 25, 2)\n",
      "f_max for random input of 32 samples :  1.933270117670774\n",
      "F2:  1.0267192424900204\n",
      "Sum of all elements of all As (after init):  790.2478215085574\n",
      "f_max for random input of 32 samples (after):  1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "N = linear_dim**2\n",
    "net = tn.Network(N=N, M=M, L=2, normalize=True, calibration_X=x_calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f901ce67404f4596902fce9a23419c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch loop', max=10, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - train accuracy : 0.9950 - val accuracy: 1.0000 \n",
      "Epoch 1 - train accuracy : 1.0000 - completed : 1.00 % "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-550-b7e63445f58e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Nicola_unipd/QuintoAnno/Quantum Information/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, val_loader, lr, n_epochs, early_stopping, print_freq)\u001b[0m\n\u001b[1;32m    797\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                 \u001b[0mbatch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m                 \u001b[0mepoch_train_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/QuintoAnno/Quantum Information/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36msweep\u001b[0;34m(self, X, y, f, lr)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;31m#print(\"\\nleft sweep step \",self.N-1-i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_sweep_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/QuintoAnno/Quantum Information/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36ml_sweep_step\u001b[0;34m(self, f, y, lr, batch_size)\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 \u001b[0;31m# update r_cum_contraction (['left','b'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_contribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_cum_contraction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_cum_contraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0mcircle_contraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_cum_contraction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_cum_contraction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/QuintoAnno/Quantum Information/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36mcontract\u001b[0;34m(T1, T2, contracted_axis1, contracted_axis2, common_axis1, common_axis2, contracted, common)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;31m# call _contract_ function for actual contraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_contract_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontracted_axis1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontracted_axis2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_axis1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_axis2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/QuintoAnno/Quantum Information/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36m_contract_\u001b[0;34m(T1, T2, contracted_axis1, contracted_axis2, common_axis1, common_axis2)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontracted_axis1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# if len(contracted_axis1) == 0 just to tensor product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mT3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0mT3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT3_axes_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     36\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     37\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_acc, val_acc = net.train(train_loader, val_loader, lr = 0.01, n_epochs = 10, print_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_loader))\n",
    "x = np.array([data[i][0] for i in range(len(data))])\n",
    "y = np.array([data[i][1] for i in range(len(data))])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = net.forward(x)\n",
    "print(f.elem.shape)\n",
    "y_pred = np.argmax(f.elem, axis=0)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.accuracy(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling in the number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = [1000*i**2 for i in range(1,9)]\n",
    "print(\"Number of samples tried: \\n\", n_samples)\n",
    "\n",
    "# keep them fixed\n",
    "linear_dim = 5\n",
    "M = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times_n_samples = []\n",
    "for n in n_samples:\n",
    "    print(\"Testing with %d samples...\"%n)\n",
    "    (data, label) = gen.create_dataset(n, sigma=0.7)\n",
    "    batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2)\n",
    "    \n",
    "    start = time.time()\n",
    "    train_acc, val_acc = net.train(train_loader, val_loader, lr = 0.5, n_epochs = 1, print_freq=1)\n",
    "    dt = time.time() - start\n",
    "    print(\"Time for 1 epoch: %.2f s \\n\"%dt)\n",
    "    times_n_samples.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(n_samples, times_n_samples, '-o', label='M = %d \\nlinear dim = %d'%(M,linear_dim))\n",
    "plt.xlabel(\"Number of samples\", fontsize=16)\n",
    "plt.ylabel(\"Time for one epoch [s]\", fontsize=16)\n",
    "plt.title(r\"Training time vs $n_{samples}$\", fontsize=16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling in the number of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_dims = np.arange(4,29,4)\n",
    "print(\"Linear dimensions tested: \\n\", linear_dims)\n",
    "\n",
    "# keep them fixed\n",
    "n_samples = 1000\n",
    "M = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times_linear_dims = []\n",
    "for linear_dim in linear_dims:\n",
    "    print(\"Testing with %d x %d images...\"%(linear_dim,linear_dim))\n",
    "    (data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim = linear_dim)\n",
    "    batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2)\n",
    "    \n",
    "    start = time.time()\n",
    "    train_acc, val_acc = net.train(train_loader, val_loader, lr = 0.5, n_epochs = 1, print_freq=1)\n",
    "    dt = time.time() - start\n",
    "    print(\"Time for 1 epoch: %.2f s \\n\"%dt)\n",
    "    times_linear_dims.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(linear_dims**2, times_linear_dims, '-o', label='M = %d \\nnum samples = %d'%(M,n_samples))\n",
    "plt.xlabel(\"Number of pixels\", fontsize=16)\n",
    "plt.ylabel(\"Time for one epoch [s]\", fontsize=16)\n",
    "plt.title(r\"Training time vs $n_{pixels}$\", fontsize=16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling in the bond dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms = [10*i for i in range(1,11)]\n",
    "print(\"Bond dimensions tested: \\n\", Ms)\n",
    "\n",
    "# keep them fixed\n",
    "n_samples = 1000\n",
    "linear_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times_bond_dims = []\n",
    "for M in Ms:\n",
    "    print(\"Testing with bond dimension %d...\"%M)\n",
    "    (data, label) = gen.create_dataset(n_samples, sigma=0.7)\n",
    "    batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2)\n",
    "    \n",
    "    start = time.time()\n",
    "    train_acc, val_acc = net.train(train_loader, val_loader, lr = 0.5, n_epochs = 1, print_freq=1)\n",
    "    dt = time.time() - start\n",
    "    print(\"Time for 1 epoch: %.2f s \\n\"%dt)\n",
    "    times_bond_dims.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(Ms, times_bond_dims, '-o', label='linear dim = %d \\nnum samples = %d'%(linear_dim,n_samples))\n",
    "plt.xlabel(\"Bond dimension\", fontsize=16)\n",
    "plt.ylabel(\"Time for one epoch [s]\", fontsize=16)\n",
    "plt.title(\"Training time vs bond dimension\", fontsize=16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight initialization\n",
    "\n",
    "**Objective:** study what is the dependence in the output magnitude of the various dimensions so that we can choose how to normalize the matrices A during initialization.\n",
    "\n",
    "**Parameters:**\n",
    "* Number of pixels N\n",
    "* Bond dimension M\n",
    "* Batch size B\n",
    "* Embedding dimension D (fixed to 2)\n",
    "\n",
    "Only the first 3 will be inquired.\n",
    "\n",
    "**Methodology:** Use random input in [0,1] and random initialization in [0,1] for different dimensions and look at the absolute value of the output (take the output among the L with the highest absolute value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependence on the number of pixels N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_dims = np.arange(4,16)\n",
    "print(\"Linear dimensions tested: \\n\", linear_dims)\n",
    "\n",
    "# keep them fixed\n",
    "n_samples = 1000\n",
    "M = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_linear_dims = []\n",
    "for linear_dim in linear_dims:\n",
    "    print(\"Testing with %d x %d images...\"%(linear_dim,linear_dim))\n",
    "    (data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim = linear_dim)\n",
    "    batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2)\n",
    "    \n",
    "    batch = next(iter(train_loader))\n",
    "    X = np.array([batch[i][0] for i in range(len(batch))])\n",
    "    f = net.forward(X)\n",
    "    f_max = np.abs(f.elem).max()\n",
    "    magnitude_linear_dims.append(f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_linear_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = linear_dims**2\n",
    "y = np.log10(magnitude_linear_dims)\n",
    "X = Ns.reshape(-1,1)\n",
    "reg = LinearRegression().fit(X, y)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(Ns, y, label = 'data')\n",
    "plt.plot(Ns, reg.predict(X), label = 'slope = %.2f'%reg.coef_)\n",
    "plt.ylabel(r'$log_{10}(f_{max})$', fontsize = 16)\n",
    "plt.xlabel('Number of pixels N', fontsize = 16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the dependence on N is exponential, meaning that we can have an exponential suppression (or divergence) if the network is not accurately initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating dependence C(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaled = y - Ns*np.log10(M)\n",
    "X = Ns.reshape(-1,1)\n",
    "reg_C = LinearRegression().fit(X, y_scaled)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(Ns, y_scaled, label = 'data')\n",
    "plt.plot(Ns, reg_C.predict(X), label = 'slope = %.2f'%reg_C.coef_)\n",
    "plt.ylabel(r'$log_{10}(f_{max})$', fontsize = 16)\n",
    "plt.xlabel('Number of pixels N', fontsize = 16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/(10**(-0.18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bond dimension M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms = [5*i for i in range(1,21)]\n",
    "print(\"Bond dimensions tested: \\n\", Ms)\n",
    "\n",
    "# keep them fixed\n",
    "n_samples = 1000\n",
    "linear_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "magnitude_bond_dims = []\n",
    "for M in Ms:\n",
    "    print(\"Testing with bond dimension %d...\"%M)\n",
    "    (data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim=linear_dim)\n",
    "    batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2)\n",
    "    \n",
    "    batch = next(iter(train_loader))\n",
    "    X = np.array([batch[i][0] for i in range(len(batch))])\n",
    "    f = net.forward(X)\n",
    "    f_max = np.abs(f.elem).max()\n",
    "    magnitude_bond_dims.append(f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log10(magnitude_bond_dims)\n",
    "X = np.log10(np.array(Ms)).reshape(-1,1)\n",
    "reg_M = LinearRegression().fit(X, y)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(X, y, label = 'data')\n",
    "plt.plot(X, reg_M.predict(X), label = 'slope = %.3f'%reg_M.coef_)\n",
    "plt.ylabel(r'$log_{10}(f_{max})$', fontsize = 16)\n",
    "plt.xlabel(r'Bond dimension $log_{10}(M)$', fontsize = 16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(10**reg_M.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output magnitude has a power law dependence on the bond dimension. Notice how the slope is equal to N.\n",
    "This makes sense since we already know that f is exponential in N. Now we also can approximate the scaling of the f as:\n",
    "$$f \\approx C(N)*M^N$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch dimension B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 20\n",
    "n_samples = 1000\n",
    "linear_dim = 5\n",
    "\n",
    "train_batch_sizes = np.array([2**i for i in range(1,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_batch_size = []\n",
    "for B in train_batch_sizes:\n",
    "    (data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim = linear_dim)\n",
    "    batch_size = {'train_batch_size': int(B), 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2)\n",
    "    \n",
    "    batch = next(iter(train_loader))\n",
    "    X = np.array([batch[i][0] for i in range(len(batch))])\n",
    "    f = net.forward(X)\n",
    "    f_max = np.abs(f.elem).max()\n",
    "    magnitude_batch_size.append(f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_batch_sizes, magnitude_batch_size, label = 'data')\n",
    "plt.ylabel(r'$f_{max}$', fontsize = 16)\n",
    "plt.xlabel('Batch size B', fontsize = 16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No clear dependence emerges on the batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion on initialization\n",
    "\n",
    "The simplest and most reliable initialization is the one that takes into account the number of pixels given as input and disregards all the rest. However remains the problem of choosing the factor with which the weights should be divided. To find an exact factor a priori is not immediate and is also a risky procedure, hence it's better to devise an empirical method to do so.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_dim = 5\n",
    "n_samples = 1000\n",
    "M = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Cs = np.arange(1,21)\n",
    "(data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim = linear_dim)\n",
    "batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "batch = next(iter(train_loader))\n",
    "X = np.array([batch[i][0] for i in range(len(batch))])\n",
    "\n",
    "magnitude_C = []\n",
    "for C in Cs:\n",
    "    \n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2, normalize=False)\n",
    "    \n",
    "    for i in range(net.N):\n",
    "        net.As[i].elem *= C\n",
    "    \n",
    "    f = net.forward(X)\n",
    "    f_max = np.abs(f.elem).max()\n",
    "    print('f_max: ', f_max)\n",
    "    magnitude_C.append(f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "X = np.log10(Cs).reshape(-1,1)\n",
    "y = np.log10(np.array(magnitude_C))\n",
    "y = y/y[0]\n",
    "reg_scale = LinearRegression().fit(X, y)\n",
    "plt.plot(X, y, label='data')\n",
    "plt.plot(X, reg_scale.predict(X), label = 'slope = %.2f\\nintercept = %.2f'%(reg_scale.coef_,reg_scale.intercept_))\n",
    "plt.ylabel(r'$log_{10}(f_{max})$', fontsize = 16)\n",
    "plt.xlabel(r'Scaling factor $log_{10}(C)$', fontsize = 16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms = np.array([5*i for i in range(1,21)])\n",
    "Cs = np.arange(1,21)\n",
    "(data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim = linear_dim)\n",
    "batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "batch = next(iter(train_loader))\n",
    "X = np.array([batch[i][0] for i in range(len(batch))])\n",
    "\n",
    "magnitude_C_M = []\n",
    "for M in Ms:\n",
    "    magnitude_C = []\n",
    "    for C in Cs:\n",
    "\n",
    "        net = tn.Network(N=linear_dim**2, M=M, L=2, normalize=False)\n",
    "\n",
    "        for i in range(net.N):\n",
    "            net.As[i].elem *= C\n",
    "\n",
    "        f = net.forward(X)\n",
    "        f_max = np.abs(f.elem).max()\n",
    "        magnitude_C.append(f_max)\n",
    "        \n",
    "    magnitude_C = np.array(magnitude_C)\n",
    "    magnitude_C_M.append(magnitude_C)\n",
    "    \n",
    "magnitude_C_M = np.array(magnitude_C_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_C_M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = []\n",
    "for i,M in enumerate(Ms):\n",
    "    X = np.log10(Cs).reshape(-1,1)\n",
    "    y = np.log10(np.array(magnitude_C_M[i,:]))\n",
    "    y = y/y[0]\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    alphas.append(reg.coef_)\n",
    "alphas = np.array(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(Ms, alphas)\n",
    "plt.xlabel('Bond dimension M', fontsize=16)\n",
    "plt.ylabel(r'$\\alpha$ coefficient', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_dims = np.arange(4,29,4)\n",
    "print(\"Linear dimensions tested: \\n\", linear_dims)\n",
    "\n",
    "# keep them fixed\n",
    "n_samples = 1000\n",
    "M = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_linear_dims = []\n",
    "for linear_dim in linear_dims:\n",
    "    print(\"Testing with %d x %d images...\"%(linear_dim,linear_dim))\n",
    "    (data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim = linear_dim)\n",
    "    batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2, normalize=True)\n",
    "    \n",
    "    batch = next(iter(train_loader))\n",
    "    X = np.array([batch[i][0] for i in range(len(batch))])\n",
    "    f = net.forward(X)\n",
    "    f_max = np.abs(f.elem).max()\n",
    "    magnitude_linear_dims.append(f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.random.random(10000)\n",
    "x = np.cos(np.pi/2*u)\n",
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_linear_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = linear_dims**2\n",
    "y = np.log10(magnitude_linear_dims)\n",
    "X = Ns.reshape(-1,1)\n",
    "reg = LinearRegression().fit(X, y)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(Ns, y, label = 'data')\n",
    "plt.plot(Ns, reg.predict(X), label = 'slope = %.2f'%reg.coef_)\n",
    "plt.ylabel(r'$log_{10}(f_{max})$', fontsize = 16)\n",
    "plt.xlabel('Number of pixels N', fontsize = 16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient clipping\n",
    "**Idea**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.measure\n",
    "\n",
    "def pooling(X):\n",
    "    X = skimage.measure.block_reduce(X, (1,2,2), np.max)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_data = gen.get_MNIST_dataset(data_root_dir = './datasets', download=False)\n",
    "train_data, train_labels, test_data, test_labels = MNIST_data\n",
    "data = np.concatenate((train_data,test_data))[:5000]\n",
    "data = pooling(data)\n",
    "labels = np.concatenate((train_labels,test_labels))[:5000]\n",
    "batch_size = {'train_batch_size':128, 'val_batch_size':128, 'test_batch_size':128}\n",
    "train_loader, val_loader, test_loader = prepare_dataset(data, labels, 6/7, 0.2, **batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TensorNetwork' from '/home/nicola/Nicola_unipd/QuintoAnno/Quantum Information/TensorNetworkForML/TensorNetwork/TensorNetwork.py'>"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_batch = next(iter(train_loader))\n",
    "x_calibration = np.array([calibration_batch[i][0] for i in range(len(calibration_batch))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing weights...\n",
      "Scaling factor: 12.80\n",
      "(128, 196, 2)\n",
      "f_max for random input of 128 samples :  1.9856434880091296e-21\n",
      "F2:  0.7841100988334627\n",
      "Sum of all elements of all As (after init):  8175.981457905476\n",
      "f_max for random input of 128 samples (after):  0.9999999999999886\n"
     ]
    }
   ],
   "source": [
    "net = tn.Network(N=196, M=20, L=10, normalize=True, calibration_X=x_calibration)#, sigma=0.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7574d7a5e2e140d1ada8fc9961479fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch loop', max=10, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_acc:  0.171875\n",
      "batch_acc_opt:  0.3515625\n",
      "batch_acc:  0.109375\n",
      "batch_acc_opt:  0.078125\n",
      "Epoch 0 - train accuracy : 0.1094 - completed : 7.69 % batch_acc:  0.109375\n",
      "batch_acc_opt:  0.09375\n",
      "batch_acc:  0.109375\n",
      "batch_acc_opt:  0.171875\n",
      "Epoch 0 - train accuracy : 0.1094 - completed : 15.38 % batch_acc:  0.078125\n",
      "batch_acc_opt:  0.1015625\n",
      "batch_acc:  0.0546875\n",
      "batch_acc_opt:  0.0859375\n",
      "Epoch 0 - train accuracy : 0.0547 - completed : 23.08 % batch_acc:  0.1328125\n",
      "batch_acc_opt:  0.078125\n",
      "batch_acc:  0.0859375\n",
      "batch_acc_opt:  0.1015625\n",
      "Epoch 0 - train accuracy : 0.0859 - completed : 30.77 % batch_acc:  0.1328125\n",
      "batch_acc_opt:  0.0703125\n",
      "batch_acc:  0.2109375\n",
      "batch_acc_opt:  0.0859375\n",
      "Epoch 0 - train accuracy : 0.2109 - completed : 38.46 % batch_acc:  0.0703125\n",
      "batch_acc_opt:  0.109375\n",
      "batch_acc:  0.0859375\n",
      "batch_acc_opt:  0.0703125\n",
      "Epoch 0 - train accuracy : 0.0859 - completed : 46.15 % batch_acc:  0.09375\n",
      "batch_acc_opt:  0.0703125\n",
      "batch_acc:  0.1328125\n",
      "batch_acc_opt:  0.109375\n",
      "Epoch 0 - train accuracy : 0.1328 - completed : 53.85 % batch_acc:  0.125\n",
      "batch_acc_opt:  0.09375\n",
      "batch_acc:  0.1171875\n",
      "batch_acc_opt:  0.1015625\n",
      "Epoch 0 - train accuracy : 0.1172 - completed : 61.54 % batch_acc:  0.0546875\n",
      "batch_acc_opt:  0.1171875\n",
      "batch_acc:  0.1796875\n",
      "batch_acc_opt:  0.109375\n",
      "Epoch 0 - train accuracy : 0.1797 - completed : 69.23 % batch_acc:  0.09375\n",
      "batch_acc_opt:  0.09375\n",
      "batch_acc:  0.0703125\n",
      "batch_acc_opt:  0.1171875\n",
      "Epoch 0 - train accuracy : 0.0703 - completed : 76.92 % batch_acc:  0.0859375\n",
      "batch_acc_opt:  0.1796875\n",
      "batch_acc:  0.15625\n",
      "batch_acc_opt:  0.0859375\n",
      "Epoch 0 - train accuracy : 0.1562 - completed : 84.62 % batch_acc:  0.0859375\n",
      "batch_acc_opt:  0.125\n",
      "batch_acc:  0.09375\n",
      "batch_acc_opt:  0.0625\n",
      "Epoch 0 - train accuracy : 0.0938 - completed : 92.31 % batch_acc:  0.1015625\n",
      "batch_acc_opt:  0.109375\n",
      "batch_acc:  0.078125\n",
      "batch_acc_opt:  0.1328125\n",
      "Epoch 0 - train accuracy : 0.1085 - val accuracy: 0.0716 \n",
      "batch_acc:  0.09375\n",
      "batch_acc_opt:  0.09375\n",
      "batch_acc:  0.140625\n",
      "batch_acc_opt:  0.0546875\n",
      "Epoch 1 - train accuracy : 0.1406 - completed : 7.69 % batch_acc:  0.1484375\n",
      "batch_acc_opt:  0.1171875\n",
      "batch_acc:  0.0703125\n",
      "batch_acc_opt:  0.140625\n",
      "Epoch 1 - train accuracy : 0.0703 - completed : 15.38 % batch_acc:  0.109375\n",
      "batch_acc_opt:  0.171875\n",
      "batch_acc:  0.0625\n",
      "batch_acc_opt:  0.1640625\n",
      "Epoch 1 - train accuracy : 0.0625 - completed : 23.08 % batch_acc:  0.1015625\n",
      "batch_acc_opt:  0.0859375\n",
      "batch_acc:  0.0859375\n",
      "batch_acc_opt:  0.046875\n",
      "Epoch 1 - train accuracy : 0.0859 - completed : 30.77 % batch_acc:  0.046875\n",
      "batch_acc_opt:  0.125\n",
      "batch_acc:  0.0625\n",
      "batch_acc_opt:  0.0703125\n",
      "Epoch 1 - train accuracy : 0.0625 - completed : 38.46 % batch_acc:  0.109375\n",
      "batch_acc_opt:  0.0859375\n",
      "batch_acc:  0.125\n",
      "batch_acc_opt:  0.0625\n",
      "Epoch 1 - train accuracy : 0.1250 - completed : 46.15 % batch_acc:  0.1015625\n",
      "batch_acc_opt:  0.1640625\n",
      "batch_acc:  0.078125\n",
      "batch_acc_opt:  0.0859375\n",
      "Epoch 1 - train accuracy : 0.0781 - completed : 53.85 % batch_acc:  0.140625\n",
      "batch_acc_opt:  0.125\n",
      "batch_acc:  0.1171875\n",
      "batch_acc_opt:  0.078125\n",
      "Epoch 1 - train accuracy : 0.1172 - completed : 61.54 % batch_acc:  0.1171875\n",
      "batch_acc_opt:  0.1171875\n",
      "batch_acc:  0.109375\n",
      "batch_acc_opt:  0.1328125\n",
      "Epoch 1 - train accuracy : 0.1094 - completed : 69.23 % batch_acc:  0.109375\n",
      "batch_acc_opt:  0.1171875\n",
      "batch_acc:  0.125\n",
      "batch_acc_opt:  0.0625\n",
      "Epoch 1 - train accuracy : 0.1250 - completed : 76.92 % batch_acc:  0.1015625\n",
      "batch_acc_opt:  0.109375\n",
      "batch_acc:  0.046875\n",
      "batch_acc_opt:  0.1015625\n",
      "Epoch 1 - train accuracy : 0.0469 - completed : 84.62 % batch_acc:  0.09375\n",
      "batch_acc_opt:  0.109375\n",
      "batch_acc:  0.09375\n",
      "batch_acc_opt:  0.109375\n",
      "Epoch 1 - train accuracy : 0.0938 - completed : 92.31 % batch_acc:  0.109375\n",
      "batch_acc_opt:  0.1015625\n",
      "batch_acc:  0.125\n",
      "batch_acc_opt:  0.125\n",
      "Epoch 1 - train accuracy : 0.1010 - val accuracy: 0.0911 \n",
      "batch_acc:  0.1171875\n",
      "batch_acc_opt:  0.0859375\n",
      "batch_acc:  0.0859375\n",
      "batch_acc_opt:  0.078125\n",
      "Epoch 2 - train accuracy : 0.0859 - completed : 7.69 % batch_acc:  0.0703125\n",
      "batch_acc_opt:  0.046875\n",
      "batch_acc:  0.078125\n",
      "batch_acc_opt:  0.078125\n",
      "Epoch 2 - train accuracy : 0.0781 - completed : 15.38 % batch_acc:  0.1171875\n",
      "batch_acc_opt:  0.1171875\n",
      "batch_acc:  0.140625\n",
      "batch_acc_opt:  0.09375\n",
      "Epoch 2 - train accuracy : 0.1406 - completed : 23.08 % batch_acc:  0.1171875\n",
      "batch_acc_opt:  0.125\n",
      "batch_acc:  0.171875\n",
      "batch_acc_opt:  0.0859375\n",
      "Epoch 2 - train accuracy : 0.1719 - completed : 30.77 % batch_acc:  0.1171875\n",
      "batch_acc_opt:  0.09375\n",
      "batch_acc:  0.0546875\n",
      "batch_acc_opt:  0.0625\n",
      "Epoch 2 - train accuracy : 0.0547 - completed : 38.46 % batch_acc:  0.109375\n",
      "batch_acc_opt:  0.1328125\n",
      "batch_acc:  0.109375\n",
      "batch_acc_opt:  0.125\n",
      "Epoch 2 - train accuracy : 0.1094 - completed : 46.15 % "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-590-d4a0dc37a074>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Nicola_unipd/QuintoAnno/Quantum Information/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, val_loader, lr, n_epochs, early_stopping, print_freq)\u001b[0m\n\u001b[1;32m    797\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                 \u001b[0mbatch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m                 \u001b[0mbatch_acc_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_acc: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/QuintoAnno/Quantum Information/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36msweep\u001b[0;34m(self, X, y, f, lr)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m             \u001b[0;31m#print(\"\\nleft sweep step \",self.N-1-i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_sweep_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/QuintoAnno/Quantum Information/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36ml_sweep_step\u001b[0;34m(self, f, y, lr, batch_size)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_cum_contraction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_cum_contraction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# l=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/QuintoAnno/Quantum Information/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36mcontract\u001b[0;34m(T1, T2, contracted_axis1, contracted_axis2, common_axis1, common_axis2, contracted, common)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;31m# call _contract_ function for actual contraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_contract_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontracted_axis1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontracted_axis2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_axis1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_axis2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/QuintoAnno/Quantum Information/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36m_contract_\u001b[0;34m(T1, T2, contracted_axis1, contracted_axis2, common_axis1, common_axis2)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;31m#    T3_axes_names = None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m     \u001b[0mT3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mT1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontracted_axis1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# if len(contracted_axis1) == 0 just to tensor product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_acc, val_acc = net.train(train_loader, val_loader, lr = 0.01, n_epochs = 10, print_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
